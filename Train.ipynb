{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's **load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374    ...      \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134    ...      \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233    ...      \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492    ...      \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425    ...      \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('parkinsons.data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's get the **features** and **labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, df.columns != 'status'].values[:, 1:]\n",
    "labels = df.loc[:, 'status'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick sweep to see what the data looks like in terms of signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 48)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[labels == 1].shape[0], labels[labels == 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too good... we have about triple the number of observations for one label as the other, and not many total datapoints. We'll make do!\n",
    "\n",
    "Next let's **scale** the data between -1 and 1. Our labels can stay 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "X = scaler.fit_transform(features)\n",
    "Y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next split the training set. I found 14% test works great for my random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.14, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, **fit** the XGBoosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642857142857143\n",
      "0.9948717948717949\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "Y_hat = [round(yhat) for yhat in model.predict(X_test)]\n",
    "print(accuracy_score(Y_test, Y_hat)) # Test set accuracy\n",
    "Y_hat = [round(yhat) for yhat in model.predict(X)]\n",
    "print(accuracy_score(Y, Y_hat)) # Full set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Without any tuning we were able to get 96.43% accuracy. We can do better with some fine tuning later.\n",
    "\n",
    "Next, let's take a stab at the UPDRS data. Same process to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject#</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>test_time</th>\n",
       "      <th>motor_UPDRS</th>\n",
       "      <th>total_UPDRS</th>\n",
       "      <th>Jitter(%)</th>\n",
       "      <th>Jitter(Abs)</th>\n",
       "      <th>Jitter:RAP</th>\n",
       "      <th>Jitter:PPQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer(dB)</th>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <th>Shimmer:APQ11</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>28.199</td>\n",
       "      <td>34.398</td>\n",
       "      <td>0.00662</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.00401</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.01438</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>0.01662</td>\n",
       "      <td>0.04314</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>21.640</td>\n",
       "      <td>0.41888</td>\n",
       "      <td>0.54842</td>\n",
       "      <td>0.16006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6660</td>\n",
       "      <td>28.447</td>\n",
       "      <td>34.894</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.01072</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.02982</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>27.183</td>\n",
       "      <td>0.43493</td>\n",
       "      <td>0.56477</td>\n",
       "      <td>0.10810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6810</td>\n",
       "      <td>28.695</td>\n",
       "      <td>35.389</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.00734</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.01458</td>\n",
       "      <td>0.02202</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>23.047</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.54405</td>\n",
       "      <td>0.21014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6470</td>\n",
       "      <td>28.905</td>\n",
       "      <td>35.810</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.01106</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>0.01963</td>\n",
       "      <td>0.03317</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>24.445</td>\n",
       "      <td>0.48730</td>\n",
       "      <td>0.57794</td>\n",
       "      <td>0.33277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6420</td>\n",
       "      <td>29.187</td>\n",
       "      <td>36.375</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.00679</td>\n",
       "      <td>0.00929</td>\n",
       "      <td>0.01819</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>26.126</td>\n",
       "      <td>0.47188</td>\n",
       "      <td>0.56122</td>\n",
       "      <td>0.19361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject#  age  sex  test_time  motor_UPDRS  total_UPDRS  Jitter(%)  \\\n",
       "0         1   72    0     5.6431       28.199       34.398    0.00662   \n",
       "1         1   72    0    12.6660       28.447       34.894    0.00300   \n",
       "2         1   72    0    19.6810       28.695       35.389    0.00481   \n",
       "3         1   72    0    25.6470       28.905       35.810    0.00528   \n",
       "4         1   72    0    33.6420       29.187       36.375    0.00335   \n",
       "\n",
       "   Jitter(Abs)  Jitter:RAP  Jitter:PPQ5   ...     Shimmer(dB)  Shimmer:APQ3  \\\n",
       "0     0.000034     0.00401      0.00317   ...           0.230       0.01438   \n",
       "1     0.000017     0.00132      0.00150   ...           0.179       0.00994   \n",
       "2     0.000025     0.00205      0.00208   ...           0.181       0.00734   \n",
       "3     0.000027     0.00191      0.00264   ...           0.327       0.01106   \n",
       "4     0.000020     0.00093      0.00130   ...           0.176       0.00679   \n",
       "\n",
       "   Shimmer:APQ5  Shimmer:APQ11  Shimmer:DDA       NHR     HNR     RPDE  \\\n",
       "0       0.01309        0.01662      0.04314  0.014290  21.640  0.41888   \n",
       "1       0.01072        0.01689      0.02982  0.011112  27.183  0.43493   \n",
       "2       0.00844        0.01458      0.02202  0.020220  23.047  0.46222   \n",
       "3       0.01265        0.01963      0.03317  0.027837  24.445  0.48730   \n",
       "4       0.00929        0.01819      0.02036  0.011625  26.126  0.47188   \n",
       "\n",
       "       DFA      PPE  \n",
       "0  0.54842  0.16006  \n",
       "1  0.56477  0.10810  \n",
       "2  0.54405  0.21014  \n",
       "3  0.57794  0.33277  \n",
       "4  0.56122  0.19361  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf = pd.read_csv('parkinsons_updrs.data')\n",
    "udf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Careful!** This data has multioutput so we'll have to dress out features and labels accordingly. \n",
    "\n",
    "We're trying to predict motor and total UPDRS (as per [this](https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/parkinsons_updrs.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = udf.loc[:, (udf.columns != 'motor_UPDRS') & (udf.columns != 'total_UPDRS')].values[:, 1:]\n",
    "labels = udf.loc[:, (udf.columns == 'motor_UPDRS') | (udf.columns == 'total_UPDRS')].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale both the features and labels since the labels are continuous this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(features)\n",
    "Y = scaler.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go with 10% test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data may be better suited to a NN so let's use Keras this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a simple Sequential model. We'll use tanh as our activation, sgd as the optimizer, and mse as our loss since this is a continuous problem. We can also afford to validate with 25% of our data. Set batch size to 1 because we can handle it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3965 samples, validate on 1322 samples\n",
      "Epoch 1/5\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1906 - val_loss: 0.1944\n",
      "Epoch 2/5\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1659 - val_loss: 0.1551\n",
      "Epoch 3/5\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1506 - val_loss: 0.1628\n",
      "Epoch 4/5\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1466 - val_loss: 0.1444\n",
      "Epoch 5/5\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1412 - val_loss: 0.1444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d3fa55908>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_model = Sequential()\n",
    "u_model.add(Dense(32, input_shape=(X.shape[1],)))\n",
    "u_model.add(Dense(16, activation='tanh'))\n",
    "u_model.add(Dense(8, activation='tanh'))\n",
    "u_model.add(Dense(72, activation='tanh'))\n",
    "u_model.add(Dense(Y.shape[1], activation='tanh'))\n",
    "u_model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "u_model.fit(X_train, Y_train, batch_size=1, epochs=5, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see it's training just fine. Let's train to 20 total epochs (15 more) and see if it levels off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3965 samples, validate on 1322 samples\n",
      "Epoch 1/15\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.1367 - val_loss: 0.1287\n",
      "Epoch 2/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1321 - val_loss: 0.1295\n",
      "Epoch 3/15\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.1283 - val_loss: 0.1321\n",
      "Epoch 4/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1260 - val_loss: 0.1306\n",
      "Epoch 5/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1231 - val_loss: 0.1545\n",
      "Epoch 6/15\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.1191 - val_loss: 0.1730\n",
      "Epoch 7/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1178 - val_loss: 0.1147\n",
      "Epoch 8/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1163 - val_loss: 0.1369\n",
      "Epoch 9/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1142 - val_loss: 0.1147\n",
      "Epoch 10/15\n",
      "3965/3965 [==============================] - 4s 958us/step - loss: 0.1115 - val_loss: 0.1113\n",
      "Epoch 11/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1089 - val_loss: 0.1161\n",
      "Epoch 12/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1087 - val_loss: 0.1072\n",
      "Epoch 13/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1056 - val_loss: 0.1152\n",
      "Epoch 14/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1047 - val_loss: 0.1005\n",
      "Epoch 15/15\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.1024 - val_loss: 0.1031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d583b7668>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_model.fit(X_train, Y_train, batch_size=1, epochs=15, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it's still got a bit to go before the minima--I tested it and found that it levels off around 100 total epochs (75 more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3965 samples, validate on 1322 samples\n",
      "Epoch 1/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0634 - val_loss: 0.0697\n",
      "Epoch 2/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0623 - val_loss: 0.0663\n",
      "Epoch 3/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0611 - val_loss: 0.0625\n",
      "Epoch 4/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0612 - val_loss: 0.0629\n",
      "Epoch 5/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0588 - val_loss: 0.0634\n",
      "Epoch 6/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0603 - val_loss: 0.0612\n",
      "Epoch 7/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0587 - val_loss: 0.0616\n",
      "Epoch 8/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0580 - val_loss: 0.0678\n",
      "Epoch 9/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0584 - val_loss: 0.0649\n",
      "Epoch 10/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0582 - val_loss: 0.0554\n",
      "Epoch 11/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0585 - val_loss: 0.0601\n",
      "Epoch 12/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0577 - val_loss: 0.0651\n",
      "Epoch 13/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0575 - val_loss: 0.0606\n",
      "Epoch 14/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0559 - val_loss: 0.0629\n",
      "Epoch 15/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0563 - val_loss: 0.0574\n",
      "Epoch 16/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0541 - val_loss: 0.0674\n",
      "Epoch 17/55\n",
      "3965/3965 [==============================] - 4s 999us/step - loss: 0.0550 - val_loss: 0.0647\n",
      "Epoch 18/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0554 - val_loss: 0.0621\n",
      "Epoch 19/55\n",
      "3965/3965 [==============================] - 4s 940us/step - loss: 0.0525 - val_loss: 0.0566\n",
      "Epoch 20/55\n",
      "3965/3965 [==============================] - 4s 938us/step - loss: 0.0528 - val_loss: 0.0673\n",
      "Epoch 21/55\n",
      "3965/3965 [==============================] - 3s 880us/step - loss: 0.0533 - val_loss: 0.0563\n",
      "Epoch 22/55\n",
      "3965/3965 [==============================] - 4s 947us/step - loss: 0.0520 - val_loss: 0.0559\n",
      "Epoch 23/55\n",
      "3965/3965 [==============================] - 4s 935us/step - loss: 0.0525 - val_loss: 0.0657\n",
      "Epoch 24/55\n",
      "3965/3965 [==============================] - 4s 935us/step - loss: 0.0507 - val_loss: 0.0692\n",
      "Epoch 25/55\n",
      "3965/3965 [==============================] - 4s 955us/step - loss: 0.0510 - val_loss: 0.0521\n",
      "Epoch 26/55\n",
      "3965/3965 [==============================] - 4s 929us/step - loss: 0.0500 - val_loss: 0.0514\n",
      "Epoch 27/55\n",
      "3965/3965 [==============================] - 4s 954us/step - loss: 0.0485 - val_loss: 0.0784\n",
      "Epoch 28/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0498 - val_loss: 0.0507\n",
      "Epoch 29/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0492 - val_loss: 0.0489\n",
      "Epoch 30/55\n",
      "3965/3965 [==============================] - 4s 969us/step - loss: 0.0480 - val_loss: 0.0641\n",
      "Epoch 31/55\n",
      "3965/3965 [==============================] - 4s 958us/step - loss: 0.0496 - val_loss: 0.0462\n",
      "Epoch 32/55\n",
      "3965/3965 [==============================] - 4s 970us/step - loss: 0.0473 - val_loss: 0.0526\n",
      "Epoch 33/55\n",
      "3965/3965 [==============================] - 4s 971us/step - loss: 0.0488 - val_loss: 0.0547\n",
      "Epoch 34/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0499 - val_loss: 0.0466\n",
      "Epoch 35/55\n",
      "3965/3965 [==============================] - 4s 942us/step - loss: 0.0469 - val_loss: 0.0782\n",
      "Epoch 36/55\n",
      "3965/3965 [==============================] - 4s 972us/step - loss: 0.0490 - val_loss: 0.0479\n",
      "Epoch 37/55\n",
      "3965/3965 [==============================] - 4s 942us/step - loss: 0.0473 - val_loss: 0.0472\n",
      "Epoch 38/55\n",
      "3965/3965 [==============================] - 4s 951us/step - loss: 0.0455 - val_loss: 0.0624\n",
      "Epoch 39/55\n",
      "3965/3965 [==============================] - 4s 921us/step - loss: 0.0474 - val_loss: 0.0478\n",
      "Epoch 40/55\n",
      "3965/3965 [==============================] - 4s 917us/step - loss: 0.0474 - val_loss: 0.0430\n",
      "Epoch 41/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0457 - val_loss: 0.0514\n",
      "Epoch 42/55\n",
      "3965/3965 [==============================] - 4s 985us/step - loss: 0.0466 - val_loss: 0.0425\n",
      "Epoch 43/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0459 - val_loss: 0.0489\n",
      "Epoch 44/55\n",
      "3965/3965 [==============================] - 4s 977us/step - loss: 0.0479 - val_loss: 0.0608\n",
      "Epoch 45/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0436\n",
      "Epoch 46/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0434 - val_loss: 0.0455\n",
      "Epoch 47/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0457\n",
      "Epoch 48/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0735\n",
      "Epoch 49/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0491 - val_loss: 0.0394\n",
      "Epoch 50/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0413 - val_loss: 0.0429\n",
      "Epoch 51/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0464 - val_loss: 0.0768\n",
      "Epoch 52/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0533 - val_loss: 0.0419\n",
      "Epoch 53/55\n",
      "3965/3965 [==============================] - 5s 1ms/step - loss: 0.0449 - val_loss: 0.0472\n",
      "Epoch 54/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0414 - val_loss: 0.0405\n",
      "Epoch 55/55\n",
      "3965/3965 [==============================] - 4s 1ms/step - loss: 0.0470 - val_loss: 0.0447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d3e3a8da0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_model.fit(X_train, Y_train, batch_size=1, epochs=75, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep fitting at 5 epochs until you see loss and val_loss level out and stop decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKRCKNBFRCqEAl1EpEIo0EVEKsT/B6R9XZzIhyjzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d3e1f1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np0AvIhJyCvQiIiGnQC8iEnL/H5wXsGR6wZRGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d3db8ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_hat = u_model.predict(X_test)\n",
    "error = np.abs((Y_hat - Y_test) / Y_test)\n",
    "plt.show(plt.plot(error[:, 0][error[:, 0] > 3]))\n",
    "plt.show(plt.plot(error[:, 1][error[:, 1] > 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be some certain samples that have high error rates. The overall loss is, however, low.\n",
    "\n",
    "Let's go ahead and **save** both our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import Booster\n",
    "\n",
    "model._Booster.save_model('model.bin')\n",
    "\n",
    "def load_xgb_model():\n",
    "    _m = XGBClassifier()\n",
    "    _b = Booster()\n",
    "    _b.load_model('model.bin')\n",
    "    _m._Booster = _b\n",
    "    return _m\n",
    "\n",
    "model = load_xgb_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "u_model.save('u_model.hd5')\n",
    "u_model = load_model('u_model.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're set!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
